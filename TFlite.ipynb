{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d880ea-fb75-4f0e-9371-986f165048c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d277c715-1c31-4fa7-8733-959fe563db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6080e78b-12c9-45d7-82b9-02e64e5c4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332dcf6d-9fc6-42e4-a184-496f6f4b6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
    "    elif unit == \"MB\":\n",
    "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9902af5e-ab5a-47e3-b064-2398e9bea464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2d5776-414e-446c-85b6-d6d33bc18f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ade265a-f874-45c5-aeb4-443078a53994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253c54e5-ef7a-401f-8bc7-072f537ba65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc802712-b42c-4c23-8cf9-ca6133e1b6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47701f28-ce00-4a21-b5f6-4060a6f5f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c68752-501b-47ba-92c5-0c4391bff361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5104c656-dc7e-4104-9a29-3e12fa05f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[88], cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5945be8-0434-48b9-8f13-a2ecf8efad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5398f60d-39c0-4e6e-b4c0-e0fc7e66db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ACM1/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c67b80-2a82-4690-b562-0441a56166eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2987524-2eae-495b-a60a-5e5ec1e6f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss= SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82a4333-66a8-457a-90b9-bf14d94ad593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.7912 - loss: 0.6127\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.8603 - loss: 0.3929\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.8765 - loss: 0.3429\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.8856 - loss: 0.3111\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.8926 - loss: 0.2948\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.8934 - loss: 0.2834\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9003 - loss: 0.2679\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.9058 - loss: 0.2545\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9073 - loss: 0.2457\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9124 - loss: 0.2387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3129fd0d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e3e019-568e-4c8d-8a95-3005b76eb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"tf_model_fashion_mnist.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bdb68b6-97bb-474a-a165-f3f1daa28a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(KERAS_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ffd77a-6fe2-43dd-8232-39402597be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 1.187 Megabytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23747434-8c23-4e49-871e-15cd96dfc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_size = get_file_size(KERAS_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4318d15e-5398-4d6e-b8e2-08ddb19f47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 417us/step - accuracy: 0.8808 - loss: 0.3426\n",
      "\n",
      "Test accuracy is 88.08%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy is {}%'.format(round(100*test_acc, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a5e7769-7e4e-48cc-9927-1b5ca9a2213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e1b0380-18e6-4ca7-b80c-901077c29000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13196826320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196826704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1743532118.665398  178596 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1743532118.665425  178596 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-01 13:28:38.665658: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief\n",
      "2025-04-01 13:28:38.665815: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-01 13:28:38.665818: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief\n",
      "I0000 00:00:1743532118.666780  178596 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-04-01 13:28:38.666921: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-01 13:28:38.673249: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpnv8kmief\n",
      "2025-04-01 13:28:38.675202: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 9544 microseconds.\n",
      "2025-04-01 13:28:38.679967: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acec2720-0756-41b3-9d40-36ae767ab875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408812"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8902265-bea0-4146-96c0-512246295945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 0.39 Megabytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61c1b3d6-cb2d-476e-83c1-34dc61a9fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_file_size = get_file_size(TF_LITE_MODEL_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d67a0e92-ce6c-4f59-94f8-a29f44ed050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [ 1 28 28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [ 1 10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ACM1/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d311a1a5-dc15-47af-81ca-fb2d11174742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [10000    28    28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [10000    10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "628c096b-6cdd-4909-9c1d-9a82082f790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfcded07-a8b7-4024-89de-e251ee7aaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_numpy = np.array(test_images, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e1dc985-136f-4906-b6fd-7425a1f96978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs_numpy.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdfd9c21-45b1-45ac-9fe9-ea5a2276bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dac4182a-cb03-4b39-a8ff-ef6ea838c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(prediction_classes, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65c8b799-bedb-45f7-a103-a4b71273b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy TFLITE model is 88.08%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy TFLITE model is {}%'.format(round(100*acc, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ae39d14-f074-4547-9700-355c9f4ae8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3285044806438756"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_file_size/keras_model_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd207059-8ea0-4eca-a95a-938e7d6b430c",
   "metadata": {},
   "source": [
    "# TF Lite Model Float 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1847d2bd-8caa-46d7-b3a1-67c558048764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13196826320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196826704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743532453.012242  178596 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1743532453.012248  178596 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-01 13:34:13.012321: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc\n",
      "2025-04-01 13:34:13.012476: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-01 13:34:13.012481: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc\n",
      "2025-04-01 13:34:13.013668: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-01 13:34:13.019906: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmple6yzjjc\n",
      "2025-04-01 13:34:13.022008: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 9686 microseconds.\n"
     ]
    }
   ],
   "source": [
    "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_lite_float_16_model.tflite\"\n",
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8d9ddd8-d930-42cb-b856-87f608545d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205808"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_name = TF_LITE_MODEL_FLOAT_16_FILE_NAME\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dcac9e2-45a0-48ef-96d2-4474f3ae1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 200.984 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME), \"KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04b6f65f-5d03-4453-ac5d-158e063bdbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_float_16_file_size = get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bff1bce-6f51-41d5-b6e5-f0b978335597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1653788297612466"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_float_16_file_size/keras_model_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddc55c11-093a-4e7e-a6f7-060ec2d993bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034294492333885"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_float_16_file_size/tflite_file_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc2fc5-1a96-431f-b0d2-c4a619da442c",
   "metadata": {},
   "source": [
    "# TF Lite Size Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7db7d192-f73e-489b-8e07-c7605fd169a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_SIZE_QUANT_MODEL_FILE_NAME = \"tf_lite_quant_model.tflite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7db6939-361d-45d4-a122-4f6f6d39f2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13196826320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196826704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13196827088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "W0000 00:00:1743532545.248967  178596 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1743532545.248976  178596 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-01 13:35:45.249077: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf\n",
      "2025-04-01 13:35:45.249276: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-01 13:35:45.249282: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf\n",
      "2025-04-01 13:35:45.250433: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-01 13:35:45.257015: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/s7/ddngkscs167c_65wscck142m0000gr/T/tmpt3bdukzf\n",
      "2025-04-01 13:35:45.259392: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 10315 microseconds.\n"
     ]
    }
   ],
   "source": [
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48b07a4b-4051-4536-add1-28ef5dfdc053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105672"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_name = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0708397e-3bd2-4364-ad5a-583dbb69ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 103.195 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME), \"KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4289190-03bb-4265-8b40-942adab7d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_float_quant_file_size = get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3211aad-6eb8-4ae0-a43c-a50c0c296d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08491366564239705"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_float_quant_file_size/keras_model_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2a6e2cb-f0d9-4e0f-b2b6-96f43d68765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5134494285936406"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_float_quant_file_size/ tflite_float_16_file_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666630d-496d-4242-9aa2-b406bb49b0b4",
   "metadata": {},
   "source": [
    "# Accuracy of the Quantized Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f85bf-d756-4f4d-920d-198271b5c414",
   "metadata": {},
   "source": [
    "# Check Input Tensor Shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e7aacdc-8644-46e9-b76a-4c8e271bca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [ 1 28 28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [ 1 10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ACM1/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebe31b-77fc-4297-a6e0-be76dea55822",
   "metadata": {},
   "source": [
    "# Resize Tensor Shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72c534b9-c9ac-4ae6-819c-96315b0eabf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [10000    28    28]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [10000    10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c867be94-e088-46f7-8925-d06790777d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7977ba9a-eb87-4ff7-aca4-4db122ede7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_numpy = np.array(test_images, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50148ca0-3cfb-43e1-ae81-e2f156fb84cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "549dc9e4-8e87-4379-b68a-03b3258d566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(prediction_classes, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29cdbef0-87fd-4d3e-8cd3-f9155e869c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy TFLITE Quantized model is 87.98%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy TFLITE Quantized model is {}%'.format(round(100*acc, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e99fa7-20b5-4950-9038-c77f32dc6060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
